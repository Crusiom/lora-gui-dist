{
  "LoRA 训练 专家模式 | SD 训练 UI": "LoRA Training Expert Mode | SD Training UI",
  "SD-Trainer": "SD-Trainer",
  "LoRA训练": "LoRA Training",
  "新手": "Beginner",
  "专家": "Expert",
  "工具": "Tools",
  "参数详解": "Parameter Explanation",
  "Tensorboard": "Tensorboard",
  "WD 1.4 标签器": "WD 1.4 Tagger",
  "其他": "Other",
  "UI 设置": "UI Settings",
  "关于": "About",
  "Github": "Github",
  "灯泡": "Bulb",
  "训练用模型": "Models for Training",
  "model_train_type": "model_train_type",
  "模型种类": "Model Category",
  "Select": "Select",
  "pretrained_model_name_or_path": "pretrained_model_name_or_path",
  "底模文件路径": "Base Model File Path",
  "vae": "vae",
  "(可选) VAE 模型文件路径，使用外置 VAE 文件覆盖模型内本身的": "(Optional) VAE Model File Path, Overwrite Model's Own with External VAE File",
  "v2": "v2",
  "底模为 sd2.0 以后的版本需要启用": "Requires Enabling for Base Models after sd2.0",
  "数据集设置": "Dataset Settings",
  "train_data_dir": "train_data_dir",
  "训练数据集路径": "Training Dataset Path",
  "reg_data_dir": "reg_data_dir",
  "正则化数据集路径。默认留空，不使用正则化图像": "Regularization Dataset Path. Default is empty, no use of regularized images",
  "prior_loss_weight": "prior_loss_weight",
  "正则化 - 先验损失权重": "Regularization - Prior Loss Weight",
  "resolution": "resolution",
  "训练图片分辨率，宽x高。支持非正方形，但必须是 64 倍数。": "Training Image Resolution, Width x Height. Supports non-square, but must be a multiple of 64.",
  "enable_bucket": "enable_bucket",
  "启用 arb 桶以允许非固定宽高比的图片": "Enable arb buckets to allow images with non-fixed aspect ratios",
  "min_bucket_reso": "min_bucket_reso",
  "arb 桶最小分辨率": "Minimum Resolution for arb Buckets",
  "max_bucket_reso": "max_bucket_reso",
  "arb 桶最大分辨率": "Maximum Resolution for arb Buckets",
  "bucket_reso_steps": "bucket_reso_steps",
  "保存设置": "Save Settings",
  "output_name": "output_name",
  "模型保存名称": "Model Save Name",
  "output_dir": "output_dir",
  "模型保存文件夹": "Model Save Folder",
  "save_model_as": "save_model_as",
  "模型保存格式": "Model Save Format",
  "save_precision": "save_precision",
  "模型保存精度": "Model Save Precision",
  "save_every_n_epochs": "save_every_n_epochs",
  "每 N epoch（轮）自动保存一次模型": "Automatically Save Model Every N Epochs",
  "训练相关参数": "Training-related Parameters",
  "max_train_epochs": "max_train_epochs",
  "最大训练 epoch（轮数）": "Maximum Training Epochs",
  "train_batch_size": "train_batch_size",
  "批量大小": "Batch Size",
  "gradient_checkpointing": "gradient_checkpointing",
  "梯度检查点": "Gradient Checkpointing",
  "gradient_accumulation_steps": "gradient_accumulation_steps",
  "梯度累加步数": "Gradient Accumulation Steps",
  "network_train_unet_only": "network_train_unet_only",
  "仅训练 U-Net": "Train U-Net Only",
  "network_train_text_encoder_only": "network_train_text_encoder_only",
  "仅训练文本编码器": "Train Text Encoder Only",
  "学习率与优化器设置": "Learning Rate and Optimizer Settings",
  "learning_rate": "learning_rate",
  "总学习率，在分开设置 U-Net 与文本编码器学习率后这个值失效。": "Total Learning Rate, this value becomes ineffective after separately setting U-Net and text encoder learning rates.",
  "unet_lr": "unet_lr",
  "U-Net 学习率": "U-Net Learning Rate",
  "text_encoder_lr": "text_encoder_lr",
  "文本编码器学习率": "Text Encoder Learning Rate",
  "lr_scheduler": "lr_scheduler",
  "学习率调度器设置": "Learning Rate Scheduler Settings",
  "lr_warmup_steps": "lr_warmup_steps",
  "学习率预热步数": "Learning Rate Warmup Steps",
  "lr_scheduler_num_cycles": "lr_scheduler_num_cycles",
  "重启次数": "Restart Cycles",
  "optimizer_type": "optimizer_type",
  "优化器设置": "Optimizer Settings",
  "min_snr_gamma": "min_snr_gamma",
  "optimizer_args_custom": "optimizer_args_custom",
  "自定义 optimizer_args，一行一个": "Custom optimizer_args, one per line",
  "添加行": "Add Line",
  "网络设置": "Network Settings",
  "network_module": "network_module",
  "训练网络模块": "Train Network Module",
  "network_weights": "network_weights",
  "从已有的 LoRA 模型上继续训练，填写路径": "Continue Training from Existing LoRA Model, Fill in Path",
  "network_dim": "network_dim",
  "网络维度，常用 4~128，不是越大越好": "Network Dimension, commonly used between 4 and 128, bigger isn't always better",
  "network_alpha": "network_alpha",
  "常用与 network_dim 相同的值或者采用较小的值，如 network_dim 的一半 防止下溢。使用较小的 alpha 需要提升学习率。": "Commonly the same as network_dim or a smaller value, like half of network_dim to prevent underflow. Using smaller alpha requires increasing the learning rate.",
  "network_dropout": "network_dropout",
  "dropout 概率 （与 lycoris 不兼容，需要用 lycoris 自带的）": "Dropout Probability (Incompatible with Lycoris, use built-in Lycoris)",
  "scale_weight_norms": "scale_weight_norms",
  "network_args_custom": "network_args_custom",
  "自定义 network_args，一行一个": "Custom network_args, one per line",
  "enable_block_weights": "enable_block_weights",
  "启用分层学习率训练（只能在 networks.lora 中使用，与其他网络模块不兼容）": "Enable Layer-wise Learning Rate Training (only for use in networks.lora, not compatible with other network modules)",
  "enable_base_weight": "enable_base_weight",
  "差异炼丹": "Differential Alchemy",
  "训练预览图设置": "Training Preview Image Settings",
  "enable_preview": "enable_preview",
  "启用训练预览图": "Enable Training Preview Images",
  "日志设置": "Log Settings",
    "log_with": "log_with",
    "日志模块": "Log Module",
    "log_prefix": "log_prefix",
    "日志前缀": "Log Prefix",
    "log_tracker_name": "log_tracker_name",
    "日志追踪器名称": "Log Tracker Name",
    "logging_dir": "logging_dir",
    "日志保存文件夹": "Logging Save Folder",
    "caption（Tag）选项": "Caption (Tag) Options",
    "caption_extension": "caption_extension",
    "Tag 文件扩展名": "Tag File Extension",
    "shuffle_caption": "shuffle_caption",
    "训练时随机打乱 tokens": "Shuffle Tokens during Training",
    "weighted_captions": "weighted_captions",
    "使用带权重的 token，不推荐与 shuffle_caption 一同开启": "Use Weighted Tokens, not recommended to enable with shuffle_caption",
    "keep_tokens": "keep_tokens",
    "在随机打乱 tokens 时，保留前 N 个不变": "Keep First N Tokens unchanged while shuffling",
    "max_token_length": "max_token_length",
    "最大 token 长度": "Maximum Token Length",
    "caption_dropout_rate": "caption_dropout_rate",
    "丢弃全部标签的概率，对一个图片概率不使用 caption 或 class token": "Probability to Drop All Labels, no caption or class token for an image",
    "caption_dropout_every_n_epochs": "caption_dropout_every_n_epochs",
    "每 N 个 epoch 丢弃全部标签": "Drop All Labels every N epochs",
    "caption_tag_dropout_rate": "caption_tag_dropout_rate",
    "按逗号分隔的标签来随机丢弃 tag 的概率": "Probability to Randomly Drop Tags separated by commas",
    "噪声设置": "Noise Settings",
    "noise_offset": "noise_offset",
    "multires_noise_iterations": "multires_noise_iterations",
    "多分辨率（金字塔）噪声迭代次数 推荐 6-10。无法与 noise_offset 一同启用": "Multi-resolution (Pyramid) Noise Iterations, recommended 6-10. Cannot be enabled with noise_offset",
    "multires_noise_discount": "multires_noise_discount",
    "多分辨率（金字塔）衰减率 推荐 0.3-0.8，须同时与上方参数 multires_noise_iterations 一同启用": "Multi-resolution (Pyramid) Noise Discount, recommended 0.3-0.8, must be enabled with the above parameter multires_noise_iterations",
    "高级设置": "Advanced Settings",
    "seed": "seed",
    "随机种子": "Random Seed",
    "clip_skip": "clip_skip",
    "CLIP 跳过层数": "CLIP Skip Layers",
    "玄学": "Esoteric",
    "速度优化选项": "Speed Optimization Options",
    "mixed_precision": "mixed_precision",
    "训练混合精度": "Train in Mixed Precision",
    "full_fp16": "full_fp16",
    "完全使用 FP16 精度": "Use Full FP16 Precision",
    "full_bf16": "full_bf16",
    "完全使用 BF16 精度": "Use Full BF16 Precision",
    "xformers": "xformers",
    "启用 xformers": "Enable Xformers",
    "lowram": "lowram",
    "低内存模式 该模式下会将 U-net、文本编码器、VAE 直接加载到显存中": "Low RAM Mode - U-Net, Text Encoder, VAE loaded directly to VRAM",
    "cache_latents": "cache_latents",
    "缓存图像 latent": "Cache Image Latent",
    "cache_latents_to_disk": "cache_latents_to_disk",
    "缓存图像 latent 到磁盘": "Cache Image Latent to Disk",
    "cache_text_encoder_outputs": "cache_text_encoder_outputs",
    "缓存文本编码器的输出，减少显存使用。使用时需要关闭 shuffle_caption": "Cache Text Encoder Outputs, reduce VRAM usage. Requires shuffle_caption to be disabled.",
    "cache_text_encoder_outputs_to_disk": "cache_text_encoder_outputs_to_disk",
    "缓存文本编码器的输出到磁盘": "Cache Text Encoder Outputs to Disk",
    "persistent_data_loader_workers": "persistent_data_loader_workers",
    "保留加载训练集的 worker，减少每个 epoch 之间的停顿。": "Keep workers loading training set, reduce pauses between epochs.",
    "#": "#",
    "LoRA 训练 专家模式": "LoRA Training Expert Mode",
    "你所热爱的 就是你的参数": "The parameters of what you love are yours",
    "参数预览": "Parameter Preview",
    "下载配置文件": "Download Configuration File",
    "直接开始训练": "Start Training Directly",
    "全部重置": "Reset All",
    "保存": "Save",
    "读取参数": "Load Parameters",
    "Output": "Output"
  }
  
